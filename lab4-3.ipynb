{"cells": [{"cell_type": "code", "execution_count": null, "id": "3436105a", "metadata": {"deletable": false, "editable": false, "jupyter": {"outputs_hidden": true, "source_hidden": true}}, "outputs": [], "source": ["# Please do not change this cell because some hidden tests might depend on it.\n", "import os\n", "\n", "# Otter grader does not handle ! commands well, so we define and use our\n", "# own function to execute shell commands.\n", "def shell(commands, warn=True):\n", "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n", "     \n", "       Prints the result to stdout and returns the exit status. \n", "       Provides a printed warning on non-zero exit status unless `warn` \n", "       flag is unset.\n", "    \"\"\"\n", "    file = os.popen(commands)\n", "    print (file.read().rstrip('\\n'))\n", "    exit_status = file.close()\n", "    if warn and exit_status != None:\n", "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n", "    return exit_status\n", "\n", "shell(\"\"\"\n", "ls requirements.txt >/dev/null 2>&1\n", "if [ ! $? = 0 ]; then\n", " rm -rf .tmp\n", " git clone https://github.com/cs187-2021/lab4-3.git .tmp\n", " mv .tmp/tests ./\n", " mv .tmp/requirements.txt ./\n", " rm -rf .tmp\n", "fi\n", "pip install -q -r requirements.txt\n", "\"\"\")"]}, {"cell_type": "code", "execution_count": null, "id": "d80322c5", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# Initialize Otter\n", "import otter\n", "grader = otter.Notebook()"]}, {"cell_type": "markdown", "id": "464460dc", "metadata": {"id": "HIUs28Vq-KDU", "tags": ["remove_for_latex"]}, "source": ["# CS187\n", "## Lab 4-3 \u2013 Semantic ambiguity and quantifier scope"]}, {"cell_type": "markdown", "id": "e830c3fa", "metadata": {}, "source": ["When discussing syntactic representations, we encountered a central issue in natural language \u2014 ambiguity. In lab 3-3, we introduced PP attachment ambiguity to show how a single sentence (\"Twain bought a book for Howells\") can have multiple distinct syntactic structures, each bearing a different meaning. \n", "\n", "Semantic ambiguity can arise even for a *single* parse of a sentence giving rise to different meanings. In this lab, we'll introduce one example of this phenomenon, quantifier scope ambiguity. We'll take a look at a sentence that elicits this type of ambiguity and propose two possible FOL representations of the sentence, confirming that they produce different truth values in a model. Then, we will use a syntactic-semantic grammar similar to those of lab 4-1 to parse and interpret the sentence, pointing out a weakness of this method."]}, {"cell_type": "markdown", "id": "09c3e2c8", "metadata": {}, "source": ["# Preparation {-}"]}, {"cell_type": "code", "execution_count": null, "id": "a7e52181", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["import os\n", "import sys\n", "import wget\n", "\n", "import nltk"]}, {"cell_type": "code", "execution_count": null, "id": "0932b30d", "metadata": {}, "outputs": [], "source": ["# Download code for augmented grammars\n", "remote_script_dir = \"https://raw.githubusercontent.com/nlp-course/data/master/scripts/\"\n", "local_script_dir = \"./scripts/\"\n", "\n", "# Create and search the local script directory\n", "os.makedirs(local_script_dir, exist_ok=True)\n", "sys.path.insert(1, local_script_dir)\n", "\n", "# Download files to script directory\n", "wget.download(remote_script_dir + \"trees/transform.py\", out=local_script_dir)\n", "\n", "# Import functions for transforming augmented grammars\n", "import transform as xform"]}, {"cell_type": "markdown", "id": "56bca21a", "metadata": {"id": "BOrUNzos-OqG"}, "source": ["# The flight world model\n", "\n", "We'll be using the flight world as the domain for the lab as we did for lab 4-1, so we provide a simple model for it here."]}, {"cell_type": "code", "execution_count": null, "id": "9224245e", "metadata": {"id": "zzNJGn2NeaEF"}, "outputs": [], "source": ["# Constants\n", "\n", "London = \"London\"\n", "NewYork = \"New York\"\n", "Paris = \"Paris\"\n", "Boston = \"Boston\"\n", "TelAviv = \"Tel Aviv\"\n", "\n", "DL10 = \"DL10\"\n", "DL11 = \"DL11\"\n", "DL13 = \"DL13\"\n", "LY01 = \"LY01\"\n", "LY12 = \"LY12\"\n", "\n", "# Properties\n", "\n", "Object = {London, NewYork, Paris, Boston, TelAviv, DL10, DL11, DL13, LY01, LY12}\n", "Flight = {DL10, DL11, DL13, LY01, LY12}\n", "City = {London, Paris, NewYork, Boston, TelAviv}\n", "Capital = {London, Paris}\n", "\n", "# Relations\n", "\n", "Origin = {\n", "    (DL10, London), \n", "    (DL11, London), \n", "    (DL13, Paris), \n", "    (LY01, Paris), \n", "    (LY12, London)\n", "}\n", "Destination = {\n", "    (DL10, NewYork),\n", "    (DL11, TelAviv),\n", "    (DL13, Boston),\n", "    (LY01, NewYork),\n", "    (LY12, TelAviv),\n", "}"]}, {"cell_type": "markdown", "id": "07b5a6c2", "metadata": {}, "source": ["# Quantifier meanings\n", "\n", "Before discussing quantifier scope ambiguity, we need to establish an appropriate notion of quantifier meanings in natural language. In FOL, there are only two quantifiers, the universal quantifier $\\forall$ (\"for all\") and the existential quantifier $\\exists$ (\"there exists\"). In natural language, we find many more quantifiers. A few examples:\n", "\n", "* Universal: \"every\", \"each\"\n", "* Existential: \"some\", \"a(n)\"\n", "* Exact counts: \"one\", \"two\", \"three\", \"infinitely many\"\n", "* Approximate counts: \"few\", \"many\", \"most\", \"several\"\n", "* Count bounds: \"more than three\", \"fewer than 100\""]}, {"cell_type": "markdown", "id": "38918b0e", "metadata": {}, "source": ["Natural language quantifiers can be thought of as expressing a _relationship between two properties_. \n", "\n", "> Recall that a _property_ can be thought of as a set of objects (those bearing the property) or a function from objects to truth values (which takes those objects that bear the property to _true_ and objects not bearing the property to _false_). In our flight world, $Flight$ is a property, as is $\\lambda x. Origin(x, Boston)$ (\"objects originating in Boston\").\n", "\n", "Natural language quantifiers like \"every\" express a relationship between two properties, the _restriction_ of the quantifier and the _scope_ of the quantifier. For instance, in the sentence \"every flight leaves from Boston\", the restriction property is expressed by  \"flight\" and the scope property is expressed by \"leaves from Boston\". The relationship that \"every\" expresses is simply that _everything bearing the first property also bears the second property_. Similarly, \"some\" expresses the relationship that _there is something bearing the first property that also bears the second property_. And \"most\" expresses that _most (at least half, say) of the objects bearing the first property bear the second property_.\n", "\n", "This way of thinking about quantifiers as expressing relationships between two properties is referred to as [_generalized quantifiers_](https://en.wikipedia.org/wiki/Generalized_quantifier), because it generalizes the FOL notion of quantifier by adding an explicit and separate restriction.\n", "\n", "> In FOL, quantifiers $\\forall$ and $\\exists$ have only a scope and not a restriction. When we write $\\forall x. \\ldots$, the $\\ldots$ is the scope of the quantifier; we can think of this as expressing that $\\forall$ holds of the single property $\\lambda x. \\ldots$. How then can restriction properties be expressed in FOL? By folding them into the scope.\n", ">    * \"every flight leaves from Boston\": $\\forall x. Flight(x) \\Longrightarrow Origin(x, Boston)$\n", ">    * \"some flight leaves from Boston\": $\\exists x. Flight(x) \\land Origin(x, Boston)$\n", ">\n", "> Notice though that in incorporating the restriction ($Flight(x)$) into the scope of the FOL quantifier, we use different ways of combining them depending on the quantifier. That's somewhat inelegant. More importantly, for most NL quantifiers, _there is no way of encoding the relationship between restriction and scope with just a single property_, as we happen to be able to for the universal and existential quantifiers. Hence, semanticists have moved to the generalized quantifier approach to quantifier meanings, as we do here.\n", "\n", "To allow for meanings for the first order quantifiers, we'll define some Python functions that capture this generalized quantifier approach. Each quantifier function takes the two properties, restriction and scope, and returns a truth value."]}, {"cell_type": "code", "execution_count": null, "id": "99a857dc", "metadata": {}, "outputs": [], "source": ["def for_all(R_property, S_property):\n", "    \"\"\"Returns `true` just in case all objects bearing `R_property`\n", "    also have `S_property`.\"\"\"\n", "    restriction_objects = [x for x in Object if R_property(x)]\n", "    scope_objects = [x for x in Object if S_property(x)]\n", "    return all([x in scope_objects for x in restriction_objects])\n", "\n", "def there_exists(R_property, S_property):\n", "    \"\"\"Returns `true` just in case at least one object bearing `R_property`\n", "    also has `S_property`.\"\"\"\n", "    restriction_objects = [x for x in Object if R_property(x)]\n", "    scope_objects = [x for x in Object if S_property(x)]\n", "    return any([x in scope_objects for x in restriction_objects])"]}, {"cell_type": "markdown", "id": "31fb9e62", "metadata": {}, "source": ["We can see how these work by verifying that it's not the case that all flights originate in London, but some flight does."]}, {"cell_type": "code", "execution_count": null, "id": "b4286a4c", "metadata": {}, "outputs": [], "source": ["## expressing \"every flight leaves from London\" -- should be false\n", "for_all(lambda x: x in Flight, lambda y: (y, London) in Origin)"]}, {"cell_type": "code", "execution_count": null, "id": "b2cd29b3", "metadata": {}, "outputs": [], "source": ["## expressing \"some flight leaves from London\" -- should be true\n", "there_exists(lambda x: x in Flight, lambda y: (y, London) in Origin)"]}, {"cell_type": "markdown", "id": "68775361", "metadata": {"deletable": false, "editable": false}, "source": ["Now it's your turn. Implement a generalized quantifier for the English determiner \"two\", which holds if exactly two of the objects in the restriction are in the scope as well.\n", "\n", "> **Hint:** we used `Object` to store all objects.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: two_quantifier\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "42d3c309", "metadata": {}, "outputs": [], "source": ["#TODO - Implement the `two` function\n", "def two(R_property, S_property):\n", "    \"\"\"Returns `true` just in case exactly two objects bearing `R_property`\n", "    also have `S_property`.\"\"\"\n", "    ..."]}, {"cell_type": "code", "execution_count": null, "id": "ceed9be0", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"two_quantifier\")"]}, {"cell_type": "markdown", "id": "246f22cb", "metadata": {}, "source": ["We can use this implementation of the quantifier to demonstrate that two flights have New York as destination:"]}, {"cell_type": "code", "execution_count": null, "id": "63eedd4f", "metadata": {}, "outputs": [], "source": ["## expressing \"two flights go to New York\" -- should be true\n", "two(lambda x: x in Flight, lambda y: (y, NewYork) in Destination)"]}, {"cell_type": "markdown", "id": "b8d4049e", "metadata": {"deletable": false, "editable": false}, "source": ["Express and test the proposition that two flights originating in London have a capital as destination. You'll end up using two quantifiers.\n", "<!--\n", "BEGIN QUESTION\n", "name: two_london_capital\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "05b2ca8e", "metadata": {}, "outputs": [], "source": ["#TODO - express \"two flights that leave from London go to a capital\" -- should be false\n", "two_london_capital = ...\n", "two_london_capital"]}, {"cell_type": "code", "execution_count": null, "id": "4eb12a52", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"two_london_capital\")"]}, {"cell_type": "markdown", "id": "ecf439ba", "metadata": {"deletable": false, "editable": false}, "source": ["Express and test the proposition that two flights originating in a capital have New York as a destination.\n", "<!--\n", "BEGIN QUESTION\n", "name: two_capital_newyork\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "dc2f0d13", "metadata": {}, "outputs": [], "source": ["#TODO - express \"two flights that leave from a capital go to New York\"\n", "two_capital_newyork = ...\n", "two_capital_newyork"]}, {"cell_type": "code", "execution_count": null, "id": "3bc53864", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"two_capital_newyork\")"]}, {"cell_type": "markdown", "id": "eb893851", "metadata": {"id": "uOn2dddRH-1w"}, "source": ["# Quantifier scope ambiguity\n", "\n", "Consider the sentence\n", "\n", "* every flight leaves from a capital\n", "\n", "Under one reading of this sentence, it is true just in case each flight leaves from a (possibly different) city that is a capital. This interpretation can be represented with the following FOL formula:\n", "\n", "$$ \\forall x. (Flight(x) \\implies \\exists y. (Capital(y) \\land Origin(x, y))) \\tag{1}$$\n", "\n", "However, there is another possible reading of this sentence. A less intuitive yet possible interpretation could be that we are asking if there is a single capital from which all flights leave. This interpretation gives rise to a different FOL representation: \n", "\n", "$$ \\exists y. (Capital(y) \\land \\forall x. (Flight(x) \\implies Origin(x, y))) \\tag{2} $$"]}, {"cell_type": "markdown", "id": "846cfd20", "metadata": {"id": "uOn2dddRH-1w"}, "source": ["This type of ambiguity is referred to as _quantifier scope ambiguity_, and appears almost inevitably when a sentence has multiple quantified noun phrases. \n", "\n", "> Other scope-taking elements can also give rise to scope ambiguities. For instance, modals (like \"may\", \"must\", \"can\"), and negation (\"not\") also have scope and can engender ambiguities. For instance, the sentence \"you may not go\" arguably has two readings, paraphrasable as \"you have permission to not go\" (that is, you may stay) and \"you do not have permission to go\" (that is, you must stay). Examining these further kinds of ambiguity is beyond the scope (so to speak) of this lab.\n", "\n", "It is easy to see that both representations have the same components, just structured differently. The different ordering possibilities of the quantifiers is what generates the ambiguity. In representation (1), $\\forall x$ has the outer scope, while in representation (2), $\\exists y$ has the outer scope. Reflecting this ordering, the two readings are sometimes referred to as the *AE reading* and the *EA reading*, respectively.\n", "\n", "> As another example of the phenomenon, consider the old joke: In my town, a person is mugged every 15 minutes...and boy is he getting tired of it."]}, {"cell_type": "markdown", "id": "04ad1411", "metadata": {"deletable": false, "editable": false}, "source": ["Express the two readings of the sentence \n", "\n", "* every flight leaves from a capital\n", "\n", "using the Python implementation of generalized quantifiers. Start with the AE reading.\n", "<!--\n", "BEGIN QUESTION\n", "name: ambiguity_AE\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "6ff7422b", "metadata": {}, "outputs": [], "source": ["AE_reading = ...\n", "AE_reading"]}, {"cell_type": "code", "execution_count": null, "id": "ce8ff5bf", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"ambiguity_AE\")"]}, {"cell_type": "markdown", "id": "7addafe4", "metadata": {"deletable": false, "editable": false}, "source": ["Now do the same for the EA reading.\n", "<!--\n", "BEGIN QUESTION\n", "name: ambiguity_EA\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "477019bc", "metadata": {}, "outputs": [], "source": ["EA_reading = ...\n", "EA_reading"]}, {"cell_type": "code", "execution_count": null, "id": "34266368", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"ambiguity_EA\")"]}, {"cell_type": "markdown", "id": "032670c3", "metadata": {"id": "dTNqFRpXW0dg"}, "source": ["If you've implemented the two readings correctly, you have confirmed that the two readings of the ambiguous sentence are indeed different; they generate different answers."]}, {"cell_type": "markdown", "id": "6805d9a3", "metadata": {"deletable": false, "editable": false, "id": "dTNqFRpXW0dg"}, "source": ["# A compositional semantics for quantifiers\n", "\n", "Instead of manually constructing a meaning representation as we did, let's use a syntactic-semantic grammar to perform this interpretation process. We will use the following augmented grammar: \n", "<!--\n", "BEGIN QUESTION\n", "name: complete_grammar\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "919016bc", "metadata": {}, "outputs": [], "source": ["grammar_spec = \"\"\" \n", "  S -> NP VP                  :  lambda NP, VP: NP(VP)\n", "  \n", "  VP -> V NP                  :  lambda V, NP: lambda x: NP(V(x))\n", "\n", "  V -> 'leaves' 'from'        :  lambda: lambda Subj: lambda Obj: (Subj, Obj) in Origin\n", "     | 'leave' 'from'\n", "     | 'goes' 'to'            :  lambda: lambda Subj: lambda Obj: (Subj, Obj) in Destination\n", "     | 'go' 'to'\n", "\n", "  S_COMP -> 'that' VP         :  lambda X: exec('raise NotImplementedError')\n", "\n", "  NP -> DET NOM               :  lambda DET, NOM: DET(NOM)\n", "  NOM -> NOM S_COMP           :  lambda N, S: exec('raise NotImplementedError')\n", "  NOM -> N                    :  lambda X: X\n", "  \n", "  NP -> 'New' 'York'          :  lambda: lambda P: P(NewYork)\n", "      | 'Paris'               :  lambda: lambda P: P(Paris)\n", "      | 'Tel' 'Aviv'          :  lambda: lambda P: P(TelAviv)\n", "      | 'London'              :  lambda: lambda P: P(London)\n", "      | 'Boston'              :  lambda: lambda P: P(Boston)\n", "\n", "  N -> 'flight' | 'flights'   :  lambda: lambda x: x in Flight\n", "     | 'capital' | 'capitals' :  lambda: lambda x: x in Capital\n", "     | 'city' | 'cities'      :  lambda: lambda x: x in City\n", "\n", "  DET -> 'every'              :  lambda: lambda R: lambda S: for_all(R, S)\n", "       | 'a'                  :  lambda: lambda R: lambda S: there_exists(R, S)\n", "       | 'two'                :  lambda: exec('raise NotImplementedError')\n", "\"\"\""]}, {"cell_type": "markdown", "id": "c5891611", "metadata": {}, "source": ["Some things to note about the grammar:\n", "\n", "* Some of the nonterminals may be unfamiliar. In particular, the nonterminal `S_COMP` is for complementized relative clauses, phrases like \"that leaves from Boston\" in the sentence \"every flight _that leaves from Boston_ goes to New York\".\n", "\n", "* Some of the productions have no augmentation. You may recall that in this format, productions with no explicit augmentation just use the one for the preceding production. Thus the \"goes to\" and \"go to\" rules have the same augmentation.\n", "\n", "* Some of the augmentations (those involving `S_COMP` and the determiner `two`) raise `NotImplementedError`. We'll have you fill those in in a bit. Hold off for now.\n", "\n", "* As described in the introductory lecture, this grammar makes use of Richard Montague's idea that noun phrase meanings should apply to verb phrase meanings, rather than the other way around. By so doing, we allow for quantifiers within noun phrases to scope over their verb phrases. But this approach necessitates changing the types of even simple noun phrases like \"Boston\". Instead of denoting an object, it too must denote a function from properties to truth values, for example, $\\lambda P. P(Boston)$. \n", "\n", "We parse the grammar specification to extract an NLTK grammar and the augmentation dictionary, and construct a parser for the grammar."]}, {"cell_type": "code", "execution_count": null, "id": "7eb84afd", "metadata": {}, "outputs": [], "source": ["grammar, augmentations = xform.parse_augmented_grammar(grammar_spec, globals=globals())\n", "parser = nltk.parse.BottomUpChartParser(grammar)"]}, {"cell_type": "markdown", "id": "a991ef72", "metadata": {"id": "R9arBrRXYDZ2"}, "source": ["Let's create a syntactic parse tree of the sentence we've been working with: "]}, {"cell_type": "code", "execution_count": null, "id": "34818e44", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 225}, "id": "J9C5ANDCecN4", "outputId": "6e9e7513-58f8-47ec-f714-de07fb62a84b"}, "outputs": [], "source": ["sentence = \"every flight leaves from a capital\".split()\n", "parses = [p for p in parser.parse(sentence)]\n", "for tree in parses:\n", "    tree.pretty_print()"]}, {"cell_type": "markdown", "id": "e56e2f28", "metadata": {"id": "4OrZpUzeYUbD"}, "source": ["To carry out the semantic interpretation process, we will use the same notation as in lab 4-1, where the variable `A__some_words` will be given the meaning for the constituent with nonterminal `A` with the span \"some words\". We start building the semantic representation by applying the semantic composition rules from the syntactic-semantic grammar to the meanings of the subconstituents bottom up. Here are the first few steps:"]}, {"cell_type": "code", "execution_count": null, "id": "3b9ae9d2", "metadata": {}, "outputs": [], "source": ["DET__every = (lambda: lambda R: lambda S: for_all(R, S)) () # lambda R: lambda S: for_all(R, S)\n", "N__flight = (lambda: lambda x: x in Flight) () # lambda x: x in Flight\n", "NOM__flight = (lambda X: X) (N__flight) # lambda x: x in Flight\n", "NP__every_flight = (lambda DET, NN: DET(NN)) (DET__every, NOM__flight) # lambda S: for_all(lambda x: x in Flight, S)"]}, {"cell_type": "markdown", "id": "0599b6be", "metadata": {"deletable": false, "editable": false}, "source": ["Now you complete the derivation, computing the meanings for each of the remaining constituents.\n", "<!--\n", "BEGIN QUESTION\n", "name: complete_derivation\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "19d20bf0", "metadata": {}, "outputs": [], "source": ["DET__a = ...\n", "N__capital = ...\n", "NOM__capital = ...\n", "NP__a_capital = ...\n", "V__leaves_from = ...\n", "VP__leaves_from_a_capital = ...\n", "S__every_flight_leaves_from_a_capital = ..."]}, {"cell_type": "code", "execution_count": null, "id": "f407677e", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"complete_derivation\")"]}, {"cell_type": "markdown", "id": "c8af634f", "metadata": {}, "source": ["Now that you've completed the semantic derivation, let's see what truth value the model provides for this sentence."]}, {"cell_type": "code", "execution_count": null, "id": "d85d3def", "metadata": {}, "outputs": [], "source": ["S__every_flight_leaves_from_a_capital"]}, {"cell_type": "markdown", "id": "90ad3745", "metadata": {"deletable": false, "editable": false, "id": "nM2LcVbEKzlP"}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "According to the result, which of the two readings for the sentence (AE or EA) did the augmented grammar produce? Can we get the other reading with the same augmented grammar? What problems do you see resulting from this behavior?\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: ambiguity_open_question\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "c79c95d1", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "ff4b692b", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# Extending the grammar\n", "\n", "To make the language more interesting, we'll extend the grammar to allow for relative clauses like \"that leaves from Boston\" or \"that goes to a capital\", as well as allowing for the determiner \"two\". Fill in the augmentations that raise `NotImplementedError` in the grammar above to allow for these. "]}, {"cell_type": "code", "execution_count": null, "id": "34031d89", "metadata": {}, "outputs": [], "source": ["sentence = \"every flight that goes to Tel Aviv goes to a capital\"\n", "parse = list(parser.parse(sentence.split()))[0]\n", "parse.pretty_print()"]}, {"cell_type": "markdown", "id": "a71870cc", "metadata": {"deletable": false, "editable": false}, "source": ["To test the extended grammar, we'll make use of the `interpret` function you implemented in lab 4-2. Copy in your solution from that lab.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: grammar_extension\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "7a8fb523", "metadata": {}, "outputs": [], "source": ["def interpret(tree, augmentations):\n", "  ..."]}, {"cell_type": "code", "execution_count": null, "id": "26f13d2e", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check(\"grammar_extension\")"]}, {"cell_type": "markdown", "id": "400d99cd", "metadata": {}, "source": ["Now we can demonstrate the full range of this grammar fragment by testing out a bunch of different sentences to determine which are true and which are false."]}, {"cell_type": "code", "execution_count": null, "id": "03dafeaf", "metadata": {}, "outputs": [], "source": ["def test(sentence):\n", "  print(sentence)\n", "  parses = parser.parse(sentence.split())\n", "  for parse in parses:\n", "    print(parse, \"\\n==>\", interpret(parse, augmentations))"]}, {"cell_type": "code", "execution_count": null, "id": "a7124c73", "metadata": {}, "outputs": [], "source": ["test(\"every flight goes to a capital\")"]}, {"cell_type": "code", "execution_count": null, "id": "f2034c6e", "metadata": {}, "outputs": [], "source": ["test(\"two flights leave from Paris\")"]}, {"cell_type": "code", "execution_count": null, "id": "090650e4", "metadata": {}, "outputs": [], "source": ["test(\"two flights leave from London\")"]}, {"cell_type": "code", "execution_count": null, "id": "95f93a42", "metadata": {}, "outputs": [], "source": ["test(\"every flight that goes to Tel Aviv goes to a capital\")"]}, {"cell_type": "code", "execution_count": null, "id": "faedfde0", "metadata": {}, "outputs": [], "source": ["test(\"every flight that leaves from a capital goes to a capital\")"]}, {"cell_type": "code", "execution_count": null, "id": "79d12f96", "metadata": {}, "outputs": [], "source": ["test(\"every flight that goes to a capital leaves from a capital\")"]}, {"cell_type": "code", "execution_count": null, "id": "fc61b2af", "metadata": {}, "outputs": [], "source": ["test(\"every flight that goes to a city leaves from a capital\")"]}, {"cell_type": "markdown", "id": "56055713", "metadata": {"deletable": false, "editable": false}, "source": ["<!-- BEGIN QUESTION -->\n", "\n", "# Lab debrief \u2013 for consensus submission only\n", "\n", "**Question:** We're interested in any thoughts your group has about this lab so that we can improve this lab for later years, and to inform later labs for this year. Please list any issues that arose or comments you have to improve the lab. Useful things to comment on might include the following: \n", "\n", "* Was the lab too long or too short?\n", "* Were the readings appropriate for the lab? \n", "* Was it clear (at least after you completed the lab) what the points of the exercises were? \n", "* Are there additions or changes you think would make the lab better?\n", "\n", "but you should comment on whatever aspects you found especially positive or negative.\n", "\n", "<!--\n", "BEGIN QUESTION\n", "name: open_response_debrief\n", "manual: true\n", "-->"]}, {"cell_type": "markdown", "id": "000cb71f", "metadata": {}, "source": ["_Type your answer here, replacing this text._"]}, {"cell_type": "markdown", "id": "1c84a22b", "metadata": {}, "source": ["<!-- END QUESTION -->\n", "\n", "\n", "\n", "# End of Lab 4-3 {-}"]}, {"cell_type": "markdown", "id": "c9261336", "metadata": {"deletable": false, "editable": false}, "source": ["---\n", "\n", "To double-check your work, the cell below will rerun all of the autograder tests."]}, {"cell_type": "code", "execution_count": null, "id": "8022e32c", "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["grader.check_all()"]}], "metadata": {"colab": {"collapsed_sections": [], "name": "lab4-3.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "title": "CS187 Lab 4-3: Semantic ambiguity and quantifier scope"}, "nbformat": 4, "nbformat_minor": 5}